{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-31T07:21:00.293170Z","iopub.execute_input":"2021-12-31T07:21:00.293653Z","iopub.status.idle":"2021-12-31T07:21:00.589647Z","shell.execute_reply.started":"2021-12-31T07:21:00.293617Z","shell.execute_reply":"2021-12-31T07:21:00.584912Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install opencv-python","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:00.591526Z","iopub.execute_input":"2021-12-31T07:21:00.591884Z","iopub.status.idle":"2021-12-31T07:21:09.586349Z","shell.execute_reply.started":"2021-12-31T07:21:00.591845Z","shell.execute_reply":"2021-12-31T07:21:09.585147Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#downloading all the required libraraies\nimport pandas as pd\nimport numpy as np \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport cv2\nimport glob# for data extraction from xml file\nfrom xml.etree import ElementTree","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:09.588935Z","iopub.execute_input":"2021-12-31T07:21:09.589286Z","iopub.status.idle":"2021-12-31T07:21:16.226693Z","shell.execute_reply.started":"2021-12-31T07:21:09.589251Z","shell.execute_reply":"2021-12-31T07:21:16.225773Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotations_directory = '../input/face-mask-detection/annotations'\nimages_directory = '../input/face-mask-detection/images'","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:16.228611Z","iopub.execute_input":"2021-12-31T07:21:16.228862Z","iopub.status.idle":"2021-12-31T07:21:16.234091Z","shell.execute_reply.started":"2021-12-31T07:21:16.228837Z","shell.execute_reply":"2021-12-31T07:21:16.233091Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"annotation_files = !ls '../input/face-mask-detection/annotations'\nannotation_files[:10]","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:16.235363Z","iopub.execute_input":"2021-12-31T07:21:16.235622Z","iopub.status.idle":"2021-12-31T07:21:16.284977Z","shell.execute_reply.started":"2021-12-31T07:21:16.235597Z","shell.execute_reply":"2021-12-31T07:21:16.283849Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"images_files = !ls '../input/face-mask-detection/images'\nimages_files[:10]","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:16.287231Z","iopub.execute_input":"2021-12-31T07:21:16.288320Z","iopub.status.idle":"2021-12-31T07:21:16.324783Z","shell.execute_reply.started":"2021-12-31T07:21:16.288251Z","shell.execute_reply":"2021-12-31T07:21:16.323565Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(annotation_files), len(images_files)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:16.326710Z","iopub.execute_input":"2021-12-31T07:21:16.327018Z","iopub.status.idle":"2021-12-31T07:21:16.335254Z","shell.execute_reply.started":"2021-12-31T07:21:16.326985Z","shell.execute_reply":"2021-12-31T07:21:16.334198Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\ndataset = {\n            \"xmin\":[],\n            \"ymin\":[],   \n            \"xmax\":[],\n            \"ymax\":[],\n            \"label\":[],    \n            \"file\":[],\n            \"width\":[],\n            \"height\":[],\n           }\n\nfor anno in glob.glob(annotations_directory+\"/*.xml\"):\n    tree = ET.parse(anno)\n    \n    for elem in tree.iter():\n        if 'size' in elem.tag:\n            for attr in list(elem):\n                if 'width' in attr.tag: \n                    width = int(round(float(attr.text)))\n                if 'height' in attr.tag:\n                    height = int(round(float(attr.text)))    \n\n        if 'object' in elem.tag:\n            for attr in list(elem):\n                \n                if 'name' in attr.tag:\n                    name = attr.text                 \n                    dataset['label']+=[name]\n                    dataset['width']+=[width]\n                    dataset['height']+=[height] \n                    dataset['file']+=[anno.split('/')[-1][0:-4]] \n                            \n                if 'bndbox' in attr.tag:\n                    for dim in list(attr):\n                        if 'xmin' in dim.tag:\n                            xmin = int(round(float(dim.text)))\n                            dataset['xmin']+=[xmin]\n                        if 'ymin' in dim.tag:\n                            ymin = int(round(float(dim.text)))\n                            dataset['ymin']+=[ymin]                                \n                        if 'xmax' in dim.tag:\n                            xmax = int(round(float(dim.text)))\n                            dataset['xmax']+=[xmax]                                \n                        if 'ymax' in dim.tag:\n                            ymax = int(round(float(dim.text)))\n                            dataset['ymax']+=[ymax]    ","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:16.337222Z","iopub.execute_input":"2021-12-31T07:21:16.337967Z","iopub.status.idle":"2021-12-31T07:21:20.761877Z","shell.execute_reply.started":"2021-12-31T07:21:16.337912Z","shell.execute_reply":"2021-12-31T07:21:20.760642Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame(dataset)\ndf.head()\n#print(df['name'].unique())","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:20.763461Z","iopub.execute_input":"2021-12-31T07:21:20.763766Z","iopub.status.idle":"2021-12-31T07:21:20.795594Z","shell.execute_reply.started":"2021-12-31T07:21:20.763708Z","shell.execute_reply":"2021-12-31T07:21:20.795004Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df['annotation_file'] = df['file'] + '.xml' #added one new column for xml file\ndf['image_file'] = df['file'] + '.png'#added one new column for img file","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:20.798031Z","iopub.execute_input":"2021-12-31T07:21:20.798379Z","iopub.status.idle":"2021-12-31T07:21:20.810150Z","shell.execute_reply.started":"2021-12-31T07:21:20.798350Z","shell.execute_reply":"2021-12-31T07:21:20.809167Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#df\n#this will count number of people in the image maksssksksss737 with visible faces\nsum=0;\nfor i in df['file']:\n    if(i=='maksssksksss737'):\n        sum=sum+1\nprint(sum)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:20.811374Z","iopub.execute_input":"2021-12-31T07:21:20.811594Z","iopub.status.idle":"2021-12-31T07:21:20.825308Z","shell.execute_reply.started":"2021-12-31T07:21:20.811562Z","shell.execute_reply":"2021-12-31T07:21:20.824384Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import cv2\ndef show_image(image):\n    plt.figure(figsize=(10,10))\n    plt.imshow(image)\n    plt.show()\ndef convert_to_RGB(image):\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ndef crop_image(image):\n        x = df['xmin'].iloc[i]\n        y = df['ymin'].iloc[i]\n        width = df['xmax'].iloc[i]\n        height = df['ymax'].iloc[i]\n        cropped_image = image[y:height, x:width]\n    #return cropped_image\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:20.826619Z","iopub.execute_input":"2021-12-31T07:21:20.826862Z","iopub.status.idle":"2021-12-31T07:21:20.838712Z","shell.execute_reply.started":"2021-12-31T07:21:20.826833Z","shell.execute_reply":"2021-12-31T07:21:20.837386Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"***The beauty of this adatset which makes it different from others is that it contain images with several people and not just one due to which a separate xml file is used which describes every person visible face and hence we need to crop all the people:(***","metadata":{}},{"cell_type":"code","source":"def crop_image(image):\n    for i in df['file']:\n        x = annotations_info_df['xmin'].iloc[i]\n        y = annotations_info_df['ymin'].iloc[i]\n        width = annotations_info_df['xmax'].iloc[i]\n        height = annotations_info_df['ymax'].iloc[i]\n        cropped_image = image[y:height, x:width]\n    return cropped_image","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:20.840194Z","iopub.execute_input":"2021-12-31T07:21:20.840446Z","iopub.status.idle":"2021-12-31T07:21:20.851836Z","shell.execute_reply.started":"2021-12-31T07:21:20.840418Z","shell.execute_reply":"2021-12-31T07:21:20.850714Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"!ls '../input/face-mask-detection'","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:20.853302Z","iopub.execute_input":"2021-12-31T07:21:20.853569Z","iopub.status.idle":"2021-12-31T07:21:21.654108Z","shell.execute_reply.started":"2021-12-31T07:21:20.853522Z","shell.execute_reply":"2021-12-31T07:21:21.652667Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"directory = 'cropped_images'\nparent_directory = '/kaggle/working'\npath = os.path.join(parent_directory, directory)\nos.mkdir(path)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:21.656145Z","iopub.execute_input":"2021-12-31T07:21:21.656424Z","iopub.status.idle":"2021-12-31T07:21:21.661586Z","shell.execute_reply.started":"2021-12-31T07:21:21.656395Z","shell.execute_reply":"2021-12-31T07:21:21.660577Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!ls './'","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:21.663096Z","iopub.execute_input":"2021-12-31T07:21:21.664000Z","iopub.status.idle":"2021-12-31T07:21:22.469841Z","shell.execute_reply.started":"2021-12-31T07:21:21.663958Z","shell.execute_reply":"2021-12-31T07:21:22.468318Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df['cropped_image_file'] = df['file']\ndf","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:22.472108Z","iopub.execute_input":"2021-12-31T07:21:22.472475Z","iopub.status.idle":"2021-12-31T07:21:22.503636Z","shell.execute_reply.started":"2021-12-31T07:21:22.472443Z","shell.execute_reply":"2021-12-31T07:21:22.502185Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for i in range(len(df['file'])):\n    image_filepath = '../input/face-mask-detection/images/' + df['image_file'].iloc[i]\n    image = cv2.imread(image_filepath)\n    df['cropped_image_file'].iloc[i] = df['cropped_image_file'].iloc[i] + '-' + str(i) + '.png'\n    cropped_image_filename = df['cropped_image_file'].iloc[i]\n    xmin = df['xmin'].iloc[i]\n    ymin = df['ymin'].iloc[i]\n    xmax = df['xmax'].iloc[i]\n    ymax = df['ymax'].iloc[i]\n\n    # Crop The Image Based on The Values Above\n    cropped_image = image[ymin:ymax, xmin:xmax]\n    \n    # Save Cropped Image\n    cropped_image_directory = os.path.join('./cropped_images', cropped_image_filename) \n    cv2.imwrite(cropped_image_directory, cropped_image)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:21:22.505526Z","iopub.execute_input":"2021-12-31T07:21:22.505834Z","iopub.status.idle":"2021-12-31T07:22:40.053478Z","shell.execute_reply.started":"2021-12-31T07:21:22.505790Z","shell.execute_reply":"2021-12-31T07:22:40.052375Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.055213Z","iopub.execute_input":"2021-12-31T07:22:40.055469Z","iopub.status.idle":"2021-12-31T07:22:40.078014Z","shell.execute_reply.started":"2021-12-31T07:22:40.055439Z","shell.execute_reply":"2021-12-31T07:22:40.076998Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"cropped_images_files = !ls './cropped_images'\ncropped_images_files[:10]","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.079577Z","iopub.execute_input":"2021-12-31T07:22:40.080010Z","iopub.status.idle":"2021-12-31T07:22:40.131424Z","shell.execute_reply.started":"2021-12-31T07:22:40.079972Z","shell.execute_reply":"2021-12-31T07:22:40.130077Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#df.shuffle()\ntest_df = df[:1200]\ntrain_df = df[1200:]\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.133425Z","iopub.execute_input":"2021-12-31T07:22:40.134466Z","iopub.status.idle":"2021-12-31T07:22:40.140071Z","shell.execute_reply.started":"2021-12-31T07:22:40.134414Z","shell.execute_reply":"2021-12-31T07:22:40.139224Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"classes = list(train_df['label'].unique())\nclasses","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.141662Z","iopub.execute_input":"2021-12-31T07:22:40.142884Z","iopub.status.idle":"2021-12-31T07:22:40.162276Z","shell.execute_reply.started":"2021-12-31T07:22:40.142827Z","shell.execute_reply":"2021-12-31T07:22:40.161313Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Now let's have some check about the labels of an image...","metadata":{}},{"cell_type":"code","source":"train_df[train_df['file'] == 'maksssksksss139']['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.163334Z","iopub.execute_input":"2021-12-31T07:22:40.163698Z","iopub.status.idle":"2021-12-31T07:22:40.179427Z","shell.execute_reply.started":"2021-12-31T07:22:40.163660Z","shell.execute_reply":"2021-12-31T07:22:40.178857Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"image_139_path = '../input/face-mask-detection/images/maksssksksss139.png'\nimage_139 = cv2.imread(image_139_path)\nimage_139","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.180348Z","iopub.execute_input":"2021-12-31T07:22:40.180810Z","iopub.status.idle":"2021-12-31T07:22:40.209125Z","shell.execute_reply.started":"2021-12-31T07:22:40.180780Z","shell.execute_reply":"2021-12-31T07:22:40.208455Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"image_139_rgb = convert_to_RGB(image_139)\nshow_image(image_139_rgb)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.210077Z","iopub.execute_input":"2021-12-31T07:22:40.210409Z","iopub.status.idle":"2021-12-31T07:22:40.647058Z","shell.execute_reply.started":"2021-12-31T07:22:40.210377Z","shell.execute_reply":"2021-12-31T07:22:40.646078Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"image_139_df = train_df[train_df['file'] == 'maksssksksss139']\nimage_139_df","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.648375Z","iopub.execute_input":"2021-12-31T07:22:40.648745Z","iopub.status.idle":"2021-12-31T07:22:40.669380Z","shell.execute_reply.started":"2021-12-31T07:22:40.648698Z","shell.execute_reply":"2021-12-31T07:22:40.668452Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"with_mask_list, without_mask_list, incorrectly_worn_list = [], [], []\nfor i in range(len(image_139_df)):\n    bounding_box = [image_139_df['xmin'].iloc[i], image_139_df['ymin'].iloc[i],\n                    image_139_df['xmax'].iloc[i], image_139_df['ymax'].iloc[i]]\n    if image_139_df['label'].iloc[i] == 'with_mask':\n        with_mask_list.append(bounding_box)\n    elif image_139_df['label'].iloc[i] == 'without_mask':\n        without_mask_list.append(bounding_box)\n    else:\n        incorrectly_worn_list.append(bounding_box)\n        \nfound_objects_dict = {'With Mask': with_mask_list, \n                      'Without Mask': without_mask_list, \n                      'Incorrectly Worn': incorrectly_worn_list}\nfound_objects_dict","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.671135Z","iopub.execute_input":"2021-12-31T07:22:40.671473Z","iopub.status.idle":"2021-12-31T07:22:40.688483Z","shell.execute_reply.started":"2021-12-31T07:22:40.671428Z","shell.execute_reply":"2021-12-31T07:22:40.687666Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Now let's check whether the images are correctly albelled or not directly on the image itself using openCV","metadata":{}},{"cell_type":"code","source":"for key, value in found_objects_dict.items():\n    for i in range(len(value)):\n        color = (0, 255, 0) # green\n        text = 'Mask'\n        if key == 'Without Mask':\n            color = (255, 0, 0) # red\n            text = 'No Mask'\n        elif key == 'Incorrectly Worn':\n            color = (255, 255, 0) # yellow\n            text = 'Incorrect'\n        start_point = (value[i][0], value[i][1])\n        end_point = (value[i][2], value[i][3])\n        cv2.rectangle(image_139_rgb, start_point, end_point, color = color, thickness = 2)\n        cv2.putText(image_139_rgb, org = (value[i][0] - 8, value[i][1] - 3), text = text, \n                    fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.5, color = color)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.692429Z","iopub.execute_input":"2021-12-31T07:22:40.692781Z","iopub.status.idle":"2021-12-31T07:22:40.706493Z","shell.execute_reply.started":"2021-12-31T07:22:40.692744Z","shell.execute_reply":"2021-12-31T07:22:40.705704Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"show_image(image_139_rgb)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:40.708199Z","iopub.execute_input":"2021-12-31T07:22:40.708806Z","iopub.status.idle":"2021-12-31T07:22:41.089237Z","shell.execute_reply.started":"2021-12-31T07:22:40.708756Z","shell.execute_reply":"2021-12-31T07:22:41.088091Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:41.090847Z","iopub.execute_input":"2021-12-31T07:22:41.091129Z","iopub.status.idle":"2021-12-31T07:22:41.104457Z","shell.execute_reply.started":"2021-12-31T07:22:41.091095Z","shell.execute_reply":"2021-12-31T07:22:41.103719Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"sorted_label_df = pd.DataFrame(train_df['label'].value_counts()).reset_index()\nsorted_label_df.rename(columns = {'index': 'label', 'label': 'count'}, inplace = True)\nsorted_label_df","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:41.105583Z","iopub.execute_input":"2021-12-31T07:22:41.106279Z","iopub.status.idle":"2021-12-31T07:22:41.125140Z","shell.execute_reply.started":"2021-12-31T07:22:41.106237Z","shell.execute_reply":"2021-12-31T07:22:41.124011Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Now let's have a look in distribution of the people with three classes","metadata":{}},{"cell_type":"code","source":"plt.style.use('seaborn')\nplt.figure(figsize = (8, 6))\nbarplot = sns.barplot(x = 'count', y = 'label', data = sorted_label_df, orient = 'horizontal', \n                      palette = ['green', 'red', 'yellow'])\nplt.title('Distribution of Labels', fontsize = 20, fontweight = 'bold')\nplt.xlabel('Count', fontsize = 15, fontweight = 'bold')\nplt.ylabel('Label', fontsize = 15, fontweight = 'bold')\n\nfor p in barplot.patches:\n    width = p.get_width() * 1.0\n    print(width)\n    print(sum(sorted_label_df['count']), 2)\n    percentage = (width * 100 / (sum(sorted_label_df['count']), 2))\n    plt.text(x = width + 15, y = p.get_y() + 0.55 * p.get_height(), s = f'{int(width)}\\n({percentage} %)')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:41.127416Z","iopub.execute_input":"2021-12-31T07:22:41.127792Z","iopub.status.idle":"2021-12-31T07:22:41.546198Z","shell.execute_reply.started":"2021-12-31T07:22:41.127746Z","shell.execute_reply":"2021-12-31T07:22:41.544496Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Now we will do image preprocessing","metadata":{}},{"cell_type":"code","source":"cropped_image_path = './cropped_images/' + train_df['cropped_image_file'].iloc[0]\ncropped_image = cv2.imread(cropped_image_path)\ncropped_image.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:22:57.846513Z","iopub.execute_input":"2021-12-31T07:22:57.846814Z","iopub.status.idle":"2021-12-31T07:22:57.855260Z","shell.execute_reply.started":"2021-12-31T07:22:57.846782Z","shell.execute_reply":"2021-12-31T07:22:57.854228Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"image_width = []\nimage_height = []\nfor i in range(len(train_df)):\n    cropped_image_path = './cropped_images/' + train_df['cropped_image_file'].iloc[i]\n    cropped_image = cv2.imread(cropped_image_path)\n    image_width.append(cropped_image.shape[0])\n    image_height.append(cropped_image.shape[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:23:05.367626Z","iopub.execute_input":"2021-12-31T07:23:05.368042Z","iopub.status.idle":"2021-12-31T07:23:05.769081Z","shell.execute_reply.started":"2021-12-31T07:23:05.367988Z","shell.execute_reply":"2021-12-31T07:23:05.768271Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"sns.histplot(image_width, kde = True)\nplt.title('Image Width Distribution', fontsize = 16, fontweight = 'bold')\nplt.xlabel('Image Width', fontweight = 'bold')\nplt.ylabel('Count', fontweight = 'bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:23:12.922407Z","iopub.execute_input":"2021-12-31T07:23:12.922921Z","iopub.status.idle":"2021-12-31T07:23:13.326308Z","shell.execute_reply.started":"2021-12-31T07:23:12.922887Z","shell.execute_reply":"2021-12-31T07:23:13.325331Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"sns.histplot(image_height, kde = True)\nplt.title('Image Height Distribution', fontsize = 16, fontweight = 'bold')\nplt.xlabel('Image Height', fontweight = 'bold')\nplt.ylabel('Count', fontweight = 'bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:23:21.147161Z","iopub.execute_input":"2021-12-31T07:23:21.147953Z","iopub.status.idle":"2021-12-31T07:23:21.601389Z","shell.execute_reply.started":"2021-12-31T07:23:21.147908Z","shell.execute_reply":"2021-12-31T07:23:21.600635Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"image_target_size = (int(np.median(image_width)), int(np.median(image_height)))\nimage_target_size","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:23:28.522757Z","iopub.execute_input":"2021-12-31T07:23:28.523228Z","iopub.status.idle":"2021-12-31T07:23:28.531253Z","shell.execute_reply.started":"2021-12-31T07:23:28.523185Z","shell.execute_reply":"2021-12-31T07:23:28.530300Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from keras_preprocessing.image import ImageDataGenerator\n\ntrain_image_generator = ImageDataGenerator(rescale = 1. / 255., validation_split = 0.25)\n\ntrain_generator = train_image_generator.flow_from_dataframe(\n    dataframe = train_df,\n    directory = './cropped_images',\n    x_col = 'cropped_image_file',\n    y_col = 'label',\n    subset = 'training',\n    batch_size = 32,\n    seed = 42,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = image_target_size\n    )\nvalid_generator = train_image_generator.flow_from_dataframe(\n    dataframe = train_df,\n    directory = './cropped_images',\n    x_col = 'cropped_image_file',\n    y_col = 'label',\n    subset = 'validation',\n    batch_size = 32,\n    seed = 42,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = image_target_size\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:23:31.466363Z","iopub.execute_input":"2021-12-31T07:23:31.467067Z","iopub.status.idle":"2021-12-31T07:23:32.731225Z","shell.execute_reply.started":"2021-12-31T07:23:31.467024Z","shell.execute_reply":"2021-12-31T07:23:32.730087Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"test_image_generator = ImageDataGenerator(rescale = 1. / 255.)\n\ntest_generator = train_image_generator.flow_from_dataframe(\n    dataframe = test_df,\n    directory = './cropped_images',\n    x_col = 'cropped_image_file',\n    y_col = 'label',\n    batch_size = 32,\n    seed = 42,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = image_target_size\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:23:38.467494Z","iopub.execute_input":"2021-12-31T07:23:38.468306Z","iopub.status.idle":"2021-12-31T07:23:38.491643Z","shell.execute_reply.started":"2021-12-31T07:23:38.468256Z","shell.execute_reply":"2021-12-31T07:23:38.490784Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(train_generator)\nprint(valid_generator)\nprint(test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:23:44.922985Z","iopub.execute_input":"2021-12-31T07:23:44.923274Z","iopub.status.idle":"2021-12-31T07:23:44.928399Z","shell.execute_reply.started":"2021-12-31T07:23:44.923241Z","shell.execute_reply":"2021-12-31T07:23:44.927785Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"input_shape = [int(np.median(image_width)), int(np.median(image_height)), 3]","metadata":{"execution":{"iopub.status.busy":"2021-12-31T07:23:47.431560Z","iopub.execute_input":"2021-12-31T07:23:47.432003Z","iopub.status.idle":"2021-12-31T07:23:47.437540Z","shell.execute_reply.started":"2021-12-31T07:23:47.431969Z","shell.execute_reply":"2021-12-31T07:23:47.436988Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"Now the modelling will take place","metadata":{}},{"cell_type":"code","source":"model=keras.models.Sequential([\n    keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation=\"relu\",input_shape=input_shape),\n    keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\",input_shape=input_shape),\n    keras.layers.MaxPool2D(pool_size=3,padding='same'),\n    keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation=\"relu\",input_shape=input_shape),\n    keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\",input_shape=input_shape),\n    keras.layers.MaxPool2D(pool_size=3,padding='same'),\n    keras.layers.Flatten(),\n    keras.layers.Dense(units = len(classes), activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2021-12-31T08:38:15.657621Z","iopub.execute_input":"2021-12-31T08:38:15.657969Z","iopub.status.idle":"2021-12-31T08:38:15.723719Z","shell.execute_reply.started":"2021-12-31T08:38:15.657937Z","shell.execute_reply":"2021-12-31T08:38:15.722937Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy',\n                optimizer = keras.optimizers.Adam(),\n                metrics = ['accuracy', keras.metrics.Recall()])\n\nhistory_1 = model.fit(train_generator, epochs = 5, steps_per_epoch = len(train_generator), \n                        validation_data = valid_generator, validation_steps = len(valid_generator))","metadata":{"execution":{"iopub.status.busy":"2021-12-31T09:05:21.005690Z","iopub.execute_input":"2021-12-31T09:05:21.006049Z","iopub.status.idle":"2021-12-31T09:05:55.219358Z","shell.execute_reply.started":"2021-12-31T09:05:21.006001Z","shell.execute_reply":"2021-12-31T09:05:55.218242Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"val_loss,val_acc=model.evaluate(train_generator)\n\nval_loss,val_acc=model.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T09:05:59.016209Z","iopub.execute_input":"2021-12-31T09:05:59.016577Z","iopub.status.idle":"2021-12-31T09:06:01.059212Z","shell.execute_reply.started":"2021-12-31T09:05:59.016545Z","shell.execute_reply":"2021-12-31T09:06:01.057891Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"val_loss,val_acc=model.evaluate(valid_generator)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T09:06:19.140753Z","iopub.execute_input":"2021-12-31T09:06:19.141778Z","iopub.status.idle":"2021-12-31T09:06:19.900228Z","shell.execute_reply.started":"2021-12-31T09:06:19.141736Z","shell.execute_reply":"2021-12-31T09:06:19.898895Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"val_loss,val_acc=model.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T09:06:26.631928Z","iopub.execute_input":"2021-12-31T09:06:26.632212Z","iopub.status.idle":"2021-12-31T09:06:27.808440Z","shell.execute_reply.started":"2021-12-31T09:06:26.632183Z","shell.execute_reply":"2021-12-31T09:06:27.807655Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"result=pd.DataFrame(history_1.history)\nresult","metadata":{"execution":{"iopub.status.busy":"2021-12-31T08:35:30.402460Z","iopub.execute_input":"2021-12-31T08:35:30.402781Z","iopub.status.idle":"2021-12-31T08:35:30.422544Z","shell.execute_reply.started":"2021-12-31T08:35:30.402749Z","shell.execute_reply":"2021-12-31T08:35:30.421349Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"result.plot()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T08:35:56.517864Z","iopub.execute_input":"2021-12-31T08:35:56.518181Z","iopub.status.idle":"2021-12-31T08:35:56.810231Z","shell.execute_reply.started":"2021-12-31T08:35:56.518151Z","shell.execute_reply":"2021-12-31T08:35:56.808896Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-12-31T09:04:13.046863Z","iopub.execute_input":"2021-12-31T09:04:13.047211Z","iopub.status.idle":"2021-12-31T09:04:13.724992Z","shell.execute_reply.started":"2021-12-31T09:04:13.047177Z","shell.execute_reply":"2021-12-31T09:04:13.723551Z"},"trusted":true},"execution_count":98,"outputs":[]}]}